{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/DLI_Header.png\" style=\"width: 400px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 美國手語資料集的影像分類"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在本節中，我們會執行在上一節看到的資料準備、模型建立和模型訓練步驟，但使用不同的資料集：用手勢比出[美國手語](http://www.asl.gs/)字母的影像。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 目標"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 準備用於訓練的影像資料\n",
    "* 建立並編寫簡單的影像分類模型\n",
    "* 訓練影像分類模型並觀察結果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 美國手語資料集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[美國手語字母表](http://www.asl.gs/)含有 26 個字母。其中兩個字母 (j 和 z) 需要移動，因此不會包含在訓練資料集中。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/asl.png\" style=\"width: 600px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "此資料集可從網站 [Kaggle](http://www.kaggle.com) 取得，這裡是尋找資料集和其他深度學習資源的絕佳空間。除了提供資料集和「核心」(類似此課程的Notebooks)等資源外，Kaggle 也會舉辦可參加的比賽，讓參加者在訓練高度精確的模型上彼此競爭。\n",
    "\n",
    "如果你想要練習或查看眾多深度學習專案的範例，Kaggle 是值得造訪的絕佳網站。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 載入資料"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "這個資料集透過 Keras 的取得方式和 MNIST 不同，所以讓我們瞭解一下如何載入自訂資料。完成本節之後，我們會和先前一樣有 `x_train`、`y_train`、`x_valid` 和 `y_valid` 變數。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 讀取資料"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "手語資料集是 [CSV](https://en.wikipedia.org/wiki/Comma-separated_values) (逗號分隔) 格式，Microsoft Excel 和 Google 試算表都是採用這種資料結構。這是由欄和列組成的網格，頂部會有欄位名稱，就像在 [訓練](asl_data/sign_mnist_train.csv) 和[驗證](asl_data/sign_mnist_valid.csv)資料集看到的一樣 (可能需要花一些時間載入)。\n",
    "\n",
    "若要載入和使用資料，我們必須使用名為 [Pandas](https://pandas.pydata.org/) 的函式庫，這是可載入和操作資料的高效能工具。我們會將 CSV 檔案讀入一種稱為 [DataFrame](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html) 的格式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas 的 [read_csv](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html) 方法可接收 CSV 檔案，並回傳 DataFrame 檔案："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"asl_data/sign_mnist_train.csv\")\n",
    "valid_df = pd.read_csv(\"asl_data/sign_mnist_valid.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 探索資料"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "讓我們來看看目前的資料。我們可以使用 [head](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.head.html) 方法來列印 DataFrame 的前幾列。每列都是一張影像，並包含一個 `label`欄，此外還有 784 個值代表影像中的每個像素值，和 MNIST 資料集一樣。請注意，目前的影像類別都是數值，而非字母表中的字母："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 擷取影像類別"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "和 MNIST 一樣，我們想要將訓練與驗證影像類別儲存為 `y_train`和 `y_valid` 變數。現在我們要建立這些變數，然後從原始 DataFrame 檔案刪除類別資料，因為檔案不再需要這些類別資料："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_df['label']\n",
    "y_valid = valid_df['label']\n",
    "del train_df['label']\n",
    "del valid_df['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 擷取影像"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "和 MNIST 一樣，我們想將訓練與驗證影像儲存為 `x_train`和 `x_valid` 變數。現在我們要建立這些變數："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_df.values\n",
    "x_valid = valid_df.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 總結訓練與驗證資料"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我們現在有 27,455 張影像，各有 784 像素，可以用於訓練..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...以及其對應的影像類別："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在驗證方面，我們有 7,172 張影像..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_valid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...及其對應的影像類別："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 視覺化資料"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "為了視覺化影像，我們要再次使用 matplotlib 函式庫。我們不需要顧慮視覺化的細節，但如果你有興趣，可以在稍後深入瞭解 [matplotlib](https://matplotlib.org/)。\n",
    "\n",
    "請注意，我們必須將資料從目前的 784 像素 1D 形狀，重新調整成 28x28 像素的 2D 形狀，讓影像變得有意義："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(40,40))\n",
    "\n",
    "num_images = 20\n",
    "for i in range(num_images):\n",
    "    row = x_train[i]\n",
    "    label = y_train[i]\n",
    "    \n",
    "    image = row.reshape(28,28)\n",
    "    plt.subplot(1, num_images, i+1)\n",
    "    plt.title(label, fontdict={'fontsize': 30})\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 練習：正規化影像資料"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "與 MNIST 資料集一樣，我們會將影像資料正規化，這表示影像的像素值，並不會介於目前的 0 到 255："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...而應該要是介於 0 和 1 的浮點值。使用下列儲存格執行作業。如果你遇到困難，請參閱下方的解決方案。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Normalize x_train and x_valid."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 解決方案"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "按一下以下的「...」以顯示解決方案。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "```python\n",
    "x_train = x_train / 255\n",
    "x_valid = x_valid / 255\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 練習：影像分類"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "就像我們先前對 MNIST 資料集所採取的動作，現在要對影像類別進行分類編碼。回想一下，我們可以使用 [keras.utils.to_categorical](https://www.tensorflow.org/api_docs/python/tf/keras/utils/to_categorical) 方法來轉換編碼的值以及類別數量，以完成編碼作業。請在下方的儲存格中完成作業。我們已經幫你匯入 `keras` 並設定好類別數量 (24)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "num_classes = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Categorically encode y_train and y_valid."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 解決方案"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "按一下以下的「...」以顯示解決方案。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "```python\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_valid = keras.utils.to_categorical(y_valid, num_classes)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 練習：建立模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "資料全都準備好了，我們已將用於訓練和驗證的影像正規化，也將用於訓練和驗證的影像類別進行分類編碼。\n",
    "\n",
    "在本練習中，我們要建立循序模型。就像上次一樣，我們所建立的模型：\n",
    "* 具有密集輸入層。這一層包含 512 個神經元，使用 `relu`激活函數，並接收形狀為 `(784,)` 的輸入影像。\n",
    "* 具有第二個密集輸入層，含有 512 個使用 `relu`激活函數的神經元\n",
    "* 具有密集輸出層，其神經元的數量與類別數量相等，並使用 `softmax`激活函數\n",
    "\n",
    "請在下方的儲存格中執行作業，建立 `model`變數以儲存模型。我們已經匯入 Keras [循序](https://www.tensorflow.org/api_docs/python/tf/keras/Sequential)模型類別和[密集](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense)層類別，因此你可以立即開始使用。如需提示，請展開下方的解決方案："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: build a model following the guidelines above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 解決方案"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "按一下以下的「...」以顯示解決方案。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "```python\n",
    "model = Sequential()\n",
    "model.add(Dense(units = 512, activation='relu', input_shape=(784,)))\n",
    "model.add(Dense(units = 512, activation='relu'))\n",
    "model.add(Dense(units = num_classes, activation='softmax'))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 總結模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "執行下方儲存格來總結你剛剛建立的模型："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 編寫模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我們要用和先前一樣的選項來[編寫](https://www.tensorflow.org/api_docs/python/tf/keras/Sequential#compile)模型，使用[分類交叉熵](https://www.tensorflow.org/api_docs/python/tf/keras/losses/CategoricalCrossentropy)以反映出我們的目的是讓輸出接近眾多類別的其中之一，並衡量模型的準確度："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 練習：訓練模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用模型的 `fit`方法來對模型進行 20 個 Epoch 的訓練，使用的是先前建立的訓練與驗證影像和類別："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Train the model for 20 epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 解決方案"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "按一下以下的「...」以顯示解決方案。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "```python\n",
    "model.fit(x_train, y_train, epochs=20, verbose=1, validation_data=(x_valid, y_valid))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 討論：發生什麼事了？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我們可以看到訓練準確度相當高，但驗證的準確度卻沒那麼高。怎麼回事？\n",
    "\n",
    "請先思考一下，再按一下「...」以展開答案。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "這個範例顯示出，模型學會將訓練資料分類，對於尚未在其訓練中出現的新資料卻表現不佳。本質上來說，模型只是記憶資料集，無法對問題有可靠且概略的理解。這是很常見的問題，也就是所謂的*過度擬合*。我們將在接下來的兩堂課程中討論過度擬合，以及處理這個問題的一些方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 摘要"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在本節中，你建立了自己的神經網路，並用於執行相當準確的影像分類。恭喜！\n",
    "\n",
    "到目前為止，你應該已經漸漸熟悉載入資料 (包括影像類別)、準備資料、建立模型，接著使用準備好的資料訓練模型等流程。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 清除記憶體\n",
    "在繼續之前，請執行下列儲存格以清除 GPU 記憶體。必須先完成此步驟才能繼續進行下一個 Notebook。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 下一步"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "現在，你已經建立了一些非常基本且頗有效率的模型，接著我們要開始探討更複雜的模型，包括*卷積神經網路*。\n",
    "\n",
    "請繼續前往下一節：[*使用卷積神經網路處理美國手語影像*](./03_asl_cnn.ipynb)。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
